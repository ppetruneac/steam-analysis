{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Analysis \n",
    "\n",
    "Pavel Petruneac\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This is an analysis of the Steam Dataset. Data was provided in a small and larger version via GCS and more info about this dataset can be found [here](https://steam.internet.byu.edu/). \n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Analytics\n",
    "\n",
    "Business case -\n",
    "\n",
    "Your client is a mental health expert from an NGO who is interested in understanding more about gaming and the potentially addictive effect it can have on some individuals. You are meeting the client in a few days and they would like you to extract and present insights from the Steam dataset to help them in their research.\n",
    "\n",
    "Please use whichever tools you feel the most comfortable with, but we do recommend Tableau which is a popular choice. Tableau is free for students and there is also a free trial available [here](https://www.tableau.com/trial/tableau-software?utm_campaign_id=2017049&utm_campaign=Prospecting-CORE-ALL-ALL-ALL-ALL&utm_medium=Paid+Search&utm_source=Google+Search&utm_language=EN&utm_country=UKI&kw=tableau%20download&adgroup=CTX-Brand-Download-EN-E&adused=284749282495&matchtype=e&placement=&gclid=EAIaIQobChMI1tCvm4uV3QIVrbztCh05HQBMEAAYASAAEgKknfD_BwE&gclsrc=aw.ds&dclid=CI2YqZ6Lld0CFcER0wodJzkEHg).\n",
    "\n",
    "> **NOTE:** \n",
    "- in this exercise, will upload data from GCS to Big Query and do the analysis in DataStudio. The advantage of this is that is uses BQ in the backend which is multi-threaded. \n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you continue, make sure that you are authenticated with GCP. You can do it in a couple of ways: \n",
    "1. run `gcloud init` on your laptop terminal and follow instructions\n",
    "- if you run on GCP compute, allow the compute id read access to GCS bucket or \n",
    "- use a service account to authenticate on the terminal; can run something like \n",
    "\n",
    "    `gcloud auth activate-service-account *service_account_name* --key-file=credentials_file_path`, followed by \n",
    "    \n",
    "    `gcloud config set account *service_account_name*`\n",
    "    \n",
    "More info on authentication [here](https://cloud.google.com/sdk/gcloud/reference/auth/).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data in BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T21:16:54.124289Z",
     "start_time": "2019-05-31T21:16:52.494226Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Authenticate to GCP with the service account + set the default account IF you run locally\n",
    "# # No need to do this if you run on GCP and have given GCS and BQ access to the compute ID. \n",
    "\n",
    "# import os \n",
    "\n",
    "\n",
    "# command = 'gcloud auth activate-service-account steam-analysis@north-star-213610.iam.gserviceaccount.com --key-file=../credentials/gcp_service_account.json'\n",
    "# with open('command.sh', 'w') as the_file:\n",
    "#   the_file.write(command)\n",
    "# # Copy files to GCS    \n",
    "# bashCommand = \"bash command.sh\"\n",
    "# os.system(bashCommand)\n",
    " \n",
    "# # Set default account \n",
    "# command = 'gcloud config set account steam-analysis@north-star-213610.iam.gserviceaccount.com'\n",
    "# with open('command.sh', 'w') as the_file:\n",
    "#   the_file.write(command)\n",
    "# # Copy files to GCS    \n",
    "# bashCommand = \"bash command.sh\"\n",
    "# os.system(bashCommand)\n",
    "\n",
    "# # Remove the command files\n",
    "# bashCommand = \"rm command.sh\"\n",
    "# os.system(bashCommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Install / upgrade GCP dependancies\n",
    "# pip install google-cloud-iam\n",
    "pip install --upgrade  google-cloud-bigquery\n",
    "pip install --upgrade google-cloud-storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T21:23:48.418893Z",
     "start_time": "2019-05-31T21:23:48.386668Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define global parameters\n",
    "\n",
    "project_id = 'north-star-213610' # the ID of GCP project \n",
    "gcs_bucket = 'pp_steam_analysis' # bucket name where data is stored\n",
    "dataset_bq = 'pp_steam_analysis' # BQ dataset name data will be loaded to\n",
    "\n",
    "# Define what dataset to read. True for small; False for large\n",
    "steam_gaming_small = False\n",
    "\n",
    "if steam_gaming_small:\n",
    "    dataset_type = \"steam_gaming_small\"\n",
    "else:\n",
    "    dataset_type = \"steam_gaming_large\"\n",
    "print(\"It will read {} dataset from GCS bucket: {}.\".format(dataset_type, gcs_bucket))\n",
    "    \n",
    "\n",
    "\n",
    "# GCP library imports\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "# Deifne the GCP clients with the service account saved at path_service_account\n",
    "\n",
    "# If you run from local machine or don't have compute GCS & BQ permission\n",
    "# path_service_account = '../credentials/gcp_service_account.json'\n",
    "# client_storage = storage.Client.from_service_account_json(path_service_account)\n",
    "# client_bq = bigquery.Client.from_service_account_json(path_service_account)\n",
    "\n",
    "client_storage = storage.Client(project=project_id)\n",
    "client_bq = bigquery.Client(project=project_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-31T21:27:37.639748Z",
     "start_time": "2019-05-31T21:27:36.069620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Achievement_Percentages.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/App_ID_Info.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Friends-000000000000.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Friends-000000000001.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_1-000000000000.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_1-000000000001.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_2-000000000000.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_2-000000000001.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_2-000000000002.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_Developers.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_Genres.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Games_Publishers.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Groups.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000000.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000001.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000002.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000003.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000004.csv\n",
      "gs://pp_steam_analysis/data/sample/steam_gaming_large/Player_Summaries-000000000005.csv\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# List all the files in the bucket. \n",
    "# Comment dataset env var to list the small or large dataset.  \n",
    "\n",
    "# Define env variables\n",
    "export gcs_bucket=\"pp_steam_analysis\"\n",
    "# export dataset=\"steam_gaming_small\"\n",
    "export dataset=\"steam_gaming_large\"\n",
    "\n",
    "gsutil ls gs://$gcs_bucket/data/sample/$dataset/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset north-star-213610.pp_steam_analysis\n"
     ]
    }
   ],
   "source": [
    "# Create the BQ dataset if not found\n",
    "\n",
    "dataset_id = \"{}.{}\".format(client_bq.project, dataset_bq)\n",
    "# Build a Dataset object  \n",
    "dataset = bigquery.Dataset(dataset_id)\n",
    "# Specify the location\n",
    "dataset.location = \"US\"\n",
    "\n",
    "# Create the dataset even if already exists\n",
    "dataset = client_bq.create_dataset(dataset, exists_ok=True)  \n",
    "print(\"Created dataset {}.{}\".format(client_bq.project, dataset.dataset_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data from GCS bucket to BQ\n",
    "\n",
    "import os\n",
    "\n",
    "tables = [\"Achievement_Percentages\", \"App_ID_Info\", \"Friends\", 'Games_1', 'Games_2', 'Games_Developers', \n",
    "           'Games_Genres', 'Games_Publishers', 'Groups', 'Player_Summaries']\n",
    "\n",
    "for bq_table in tables:\n",
    "\n",
    "    url = \"gs://{}/data/sample/{}/{}*.csv\".format(gcs_bucket, dataset_type, bq_table) # Define the GCS URL\n",
    "\n",
    "    # Create the table in BQ\n",
    "    table_id = \"{}.{}.{}\".format(project_id, dataset_bq, bq_table)\n",
    "    table = bigquery.Table(table_id)\n",
    "    table = client_bq.create_table(table, exists_ok=True)  # API request\n",
    "\n",
    "    # Load the data from GCS to BQ\n",
    "    command = \"bq --location=US load --autodetect --replace=True --skip_leading_rows=1 --source_format=CSV \" + dataset_bq + \".\" + bq_table + \" \" + url\n",
    "    with open('command.sh', 'w') as the_file:\n",
    "      the_file.write(command)  \n",
    "    bashCommand = \"bash command.sh\"\n",
    "    os.system(bashCommand)\n",
    "    \n",
    "# Remove the command files\n",
    "bashCommand = \"rm command.sh\"\n",
    "os.system(bashCommand)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables contained in 'pp_steam_analysis':\n",
      "north-star-213610.pp_steam_analysis.Achievement_Percentages\n",
      "north-star-213610.pp_steam_analysis.App_ID_Info\n",
      "north-star-213610.pp_steam_analysis.Friends\n",
      "north-star-213610.pp_steam_analysis.Games_1\n",
      "north-star-213610.pp_steam_analysis.Games_2\n",
      "north-star-213610.pp_steam_analysis.Games_Developers\n",
      "north-star-213610.pp_steam_analysis.Games_Genres\n",
      "north-star-213610.pp_steam_analysis.Games_Publishers\n",
      "north-star-213610.pp_steam_analysis.Groups\n",
      "north-star-213610.pp_steam_analysis.Player_Summaries\n"
     ]
    }
   ],
   "source": [
    "# List tables in the BQ dataset\n",
    "\n",
    "tables = client_bq.list_tables('{}.{}'.format(project_id, dataset_bq))\n",
    "\n",
    "print(\"Tables contained in '{}':\".format(dataset_bq))\n",
    "for table in tables:\n",
    "    print(\"{}.{}.{}\".format(table.project, table.dataset_id, table.table_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "The Analysis was done in [Datastudio: Steam Analysis - Mental Health?](https://datastudio.google.com/open/1umbIL-FNX9H6ssKgL59VJ-lrVkeWXLCt) and below are listed a few BQ queries used to generate the processed data sets which were exported in BQ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-01T10:22:01.068472Z",
     "start_time": "2019-06-01T10:22:01.060105Z"
    }
   },
   "source": [
    "**Users play time**\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  A.steamid, A.appid, \n",
    "  round(A.playtime_forever / 60, 2) as play_hours, B.loccountrycode,   \n",
    "  round(TIMESTAMP_DIFF(A.dateretrieved, B.timecreated, HOUR) / 24 / 31) as months_after_signup\n",
    "FROM\n",
    "  (select * from `north-star-213610.pp_steam_analysis.Games_1` UNION ALL \n",
    "  select * from `north-star-213610.pp_steam_analysis.Games_2`) AS A\n",
    "LEFT JOIN\n",
    "  `north-star-213610.pp_steam_analysis.Player_Summaries` AS B\n",
    "ON\n",
    "  A.steamid = B.steamid \n",
    "```\n",
    "\n",
    "Group `Games_1` and `Games_2` and then join with `Player_Summaries` to get the date when the account was created. \n",
    "Select the IDs, calculate play hours, get country code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of friends users connect to since sign up date (in months)**\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  A.steamid_a as steamid, \n",
    "  round(TIMESTAMP_DIFF(A.dateretrieved, B.timecreated, HOUR) / 24 / 31) as months_after_signup,\n",
    "  B.loccountrycode, \n",
    "  count(A.steamid_b) as n_friends\n",
    "FROM\n",
    "  `north-star-213610.pp_steam_analysis.Friends`  AS A\n",
    "LEFT JOIN\n",
    "  `north-star-213610.pp_steam_analysis.Player_Summaries` AS B\n",
    "ON\n",
    "  A.steamid_a = B.steamid \n",
    "group by 1,2,3\n",
    "```\n",
    "\n",
    "Calculate the `months_after_signup` field, then count the number of friends after you join `Friends` with `Player_summaries`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of groups user join since sign up date (in months)**\n",
    "\n",
    "```\n",
    "SELECT\n",
    "  A.steamid, \n",
    "  round(TIMESTAMP_DIFF(A.dateretrieved, B.timecreated, HOUR) / 24 / 31) as months_after_signup,\n",
    "  B.loccountrycode,   \n",
    "  count(A.groupid) as n_groups\n",
    "FROM\n",
    "  `north-star-213610.pp_steam_analysis.Groups`  AS A\n",
    "LEFT JOIN\n",
    "  `north-star-213610.pp_steam_analysis.Player_Summaries` AS B\n",
    "ON\n",
    "  A.steamid = B.steamid \n",
    "group by 1,2,3\n",
    "```\n",
    "\n",
    "Calculate the `months_after_signup` field, then count the number of groups after you join `Groups` with `Player_summaries`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**since sign up - joined datasets**\n",
    "\n",
    "\n",
    "```\n",
    "SELECT \n",
    "CASE WHEN A.steamid is not null then A.steamid else 0 end as steamid, \n",
    "D.Type, A.loccountrycode, A.months_after_signup,\n",
    "CASE WHEN B.n_friends is not null then B.n_friends else 0 end as n_friends, \n",
    "CASE WHEN C.n_groups is not null then C.n_groups else 0 end as n_groups,\n",
    "CASE WHEN A.play_hours is not null then A.play_hours else 0 end as play_hours\n",
    "\n",
    "FROM `north-star-213610.pp_steam_analysis.play_time_since_signup` as A\n",
    "FULL JOIN \n",
    "`north-star-213610.pp_steam_analysis.friends_since_signup` as B\n",
    "on A.steamid = B.steamid and A.months_after_signup = B.months_after_signup \n",
    "FULL JOIN \n",
    "`north-star-213610.pp_steam_analysis.groups_since_signup` as C\n",
    "on B.steamid = C.steamid and B.months_after_signup = C.months_after_signup \n",
    "LEFT JOIN `north-star-213610.pp_steam_analysis.App_ID_Info` as D\n",
    "on A.appid = D.appid\n",
    "\n",
    "where A.months_after_signup is not null\n",
    "```\n",
    "\n",
    "This query joins all these datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please follow the [Datastudio: Steam Analysis - Mental Health?](https://datastudio.google.com/u/0/reporting/1umbIL-FNX9H6ssKgL59VJ-lrVkeWXLCt/) link to view the dashboard. \n",
    "\n",
    "**Below are screen shots of the analysis in Datastudio**\n",
    "\n",
    "** - Please note that field names could not be renamed even though the right permission to data source was granted. This may have to do with the fact that a personal GCP account was used as opposed to a corporate one. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_04.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_05.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../reports/figures/steam_07.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "194px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
